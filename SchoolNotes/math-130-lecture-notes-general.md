# Math 130 Lecture Notes General

I'm shifting my math notes to this location and condensing them a bit.  This file will also host general notes.  The lectures are a bit miserable...
[[session-3-notes]]
[[session-4-notes]]

---
**Session start**
Something about the project mentioned right at the start of the session...  I still don't know what to expect from the projects in this class.  Oh dear, it's something in the online service that is already opened to be worked on.  Forty questions long and somewhat enigmatic...  I suppose I'll have to email the professor for information, though I'll start by trying to puzzle it out myself.  At least something is being talked about that isn't interminable discussion of the properties of r.

The project seems to differentiate from the homework by granting only one attempt per question whereas the projects and tests allow only one attempt per question.  I used enough of the multiple attempts in the homework that this is a meaningful increase in the difficulty.  I used some of those attempts for typographical errors, which magnifies the stress...  Maybe I should imagine a brain implant that's nothing but prewired awesome typistry... Now there's a skillsoft that would help a lot of people in minor ways to accelerate their life without accelerating their stress levels.  Looking at the project file online, it seems to be that the question answers are saved up as the work is done, but then they're submitted all at once rather than piecemeal.  That means I can review them before I hit submit.

{Transcribed from lecture}
"Chapter 4 is all about relationships and regressions."

{Transcribed from slide}
Objectives
Regression
* The least-square regression line
* Facts about least-square regression
* (I missed one)

{Transcribed from slide}
The least-squares regression line is the line that makes the sum of the squared vertical distances of the data points from the line as small as possible.
(Chart depicting "Blood Alcohol Content as a function of Number of Beers")
(Section highlighted from the chart, depicting a dot above a line and a dot below that line at the same point)
Observed y=0.070
distance to line = y-y^ = 0.032
Predicted y^ = 0.048
distance to line = y - y^ = 0.028
observed y = 0.020

I'm not sure what this symbol I've depicted here as y^ actually is.  The teacher called it "y-half", eliding over it.  I need to be spending more time studying my statistics book...  Oh, I misheard.  She's calling it y-hat.

y^ = a+bx

(Transcribed from slide)
Residuals
(Unlabeled graph)
Points above the line have a positive residual (under estimation).
Points below the line have a negative residual (over estimation).

(Transcribed from slide)
y^ is the predicted y value on the regression line.
y^ = intercept + slope x
y^ = a + bx
Stat-Calc- 8. LinReg (a+bx)
y^ = a + bx
a=
b=
r^2=
r=
(Unlabeled extremely simple graph, pointing down)
b = slope < 0
r < 0
(Horizontal line in a box)
b = slope = 0
r = 0
(Unlabeled extremely simple graph, pointing up)
b = slope > 0
r > 0

(Transcribed from Slide)
Interpreting the regression line
The slope of the regression line describes how much we expect y to change, on average, for every unit change in x.

(Transcribed from slide)
Plotting the least-squares regression line
Use the regression equation to find the value of y for two distinct values of x, and draw the line that goes through those two points.
Hint: The regression line always passes through X-line, Y-line, the mean of x and y.
Y-hat = 0.0149x + 0.00018
The points used for drawing the regression line are derived from the equation.
They are NOT actual points from the data set (except by pure coincidence)
(BAC chart again, different highlights)
y-hat = 0.0144(8) + 0.0008 = 0.116
y = 0.0144(1) + 0.0008 = 0.0152

(Transcribed from slide)
Facts about the least-squares regression line
* Fact 1. There is a distinction between the explanatory variable and the response variable.  If their roles are reversed, we get a different regression line.
* Fact 2. The slope of the regression line is proportional to the correlation between the two variables.
* Fact 3. The regression line always passes through the point (x-line, y-line).
* Fact 4. The correlation measures the strength of the association, while the square of the correlation measures the percent of the variation that is explained by the regression line.

(My own annotations)
In an experimental study, the explanatory variable is the is the variable that is manipulated by the researcher.  Also known as the independent or predictor variable, it explains the variations in the response variable.  The explanatory variable is always charted on the x axis.  (Credit to online.stat.psu.edu for this information)

I'm certainly following along, but I don't feel like I'm learning effectively.

(Transcribed from slide)
The coefficient of determination, r^2
(Minimally labeled BAC graph from before, even smaller and less labeled)
yi - y-hat
* r^2, the coefficient of determination, is the square of the correlation coefficient.
* r^2 represents the fraction of the variance in y that can be explained by the regression model.
* r = 0.87, so r^2 = 0.76
* This model explains 76% of individual variations in BAC

(My own annotations)
I'm not sure about that, technically.

(Transcribed from slide)
Interpreting r^2 (1 of 3)
(Scatter plot)
Correlation r = -0.3
r = -0.3, r^2 = 0.09, or 9% of variation is explained in this data.
(Scatter plot)
Correlation r = -0.7
r = -0.7, r^2 = 0.49, or 49%
The regression model explains 49% of variation in this data.

(Transcribed from slide)
Interpreting r^2 (2 of 3)
(Very linear scatter plot)
Correlation = -0.99
r = -0.99, r^2 = 0.9801, or about 98%
The regression model explains almost all of the variation in y.

(Transcribed from slide)
Interpreting r^2 (3 of 3)
r represents the direction and strength of a linear relationship.
t^2 indicates what fraction of the variation in y can be explained by the linear regression model.
r =
(I fell behind!)

(Transcribed from slide)
Because elderly people may have difficult standing straight to have their heigh measured, a study looked at the relationship between overall height and height to the knee.  The data for five elderly men are given.  Use your calculator to get the
a) Scatterplot  b) Regression Line and c) Correlation coefficient
(Data table)
Knee height (cm): 57.7, 47.4, 43.5, 44.8, 55.2
Overall height (cm): 192.1, 153.3, 146.4, 162.7, 169.1

(I"m keeping up fairly well here, it's a calculator usage exercise.  I'm rounding the below to three sig figs.)
y=a+bx
a=44.131
b=2.425
r^2=.769
r=.877

(I've successfully got this graphed with a mix of the stats section and the y-equals section using the y=a+bx equation given above.)
(The teacher has repeatedly admonished the class that the y= from the calculator output is actually y-hat, not y.)

(I checked out for a while studying on my own, and when I looked back...  They're talking about the properties of r again.  Argh!)
(I'm exhausted, and the video connection is off.  I'm going to go sit on the couch and listen carefully in case there's anything else in the rest of the lecture that is new to me.)
(It sounds like there's nothing else new, and the teacher is just wrapping up.)
**Session End**

[//begin]: # "Autogenerated link references for markdown compatibility"
[session-3-notes]: session-3-notes.md "Session 3 Notes"
[session-4-notes]: session-4-notes.md "Session 4 Notes"
[//end]: # "Autogenerated link references"